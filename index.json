[{"content":"回归分析基础讲解与实战代码（附图表展示） 本文将详细讲解监督学习中的回归问题，特别是线性回归，包括其数学原理、编程实现以及如何通过图像分析模型表现，适合初学者快速入门，也适合有经验的开发者参考测试。\n一、什么是回归？ 在监督学习中，回归是一种用于预测连续值的方法。\n通俗地说，就是：\n给你一堆\u0026quot;输入-输出\u0026quot;的样本数据，让你学习出一个数学表达式，这个表达式能用来预测新数据的输出。\n就像一句比喻：\n\u0026ldquo;给出了一堆数据和结果，然后推导出一个公式\u0026rdquo;——这就是回归的核心本质。\n二、线性回归模型：单变量与多变量 2.1 线性回归的基本概念 线性回归是最基础也是最常用的回归分析方法。它通过建立因变量（预测目标）与自变量（特征）之间的线性关系来进行预测。\n数学表达式 线性回归的基本形式是： [ y = wx + b ] 其中：\n( y ) 是预测值（因变量） ( x ) 是特征（自变量） ( w ) 是权重（斜率） ( b ) 是偏置项（截距） 模型目标 线性回归的目标是找到最优的 ( w ) 和 ( b )，使得预测值与真实值之间的误差最小。通常使用均方误差（MSE）作为优化目标： [ MSE = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 ] 其中 ( y_i ) 是真实值，( \\hat{y}_i ) 是预测值。\n2.2 单变量线性回归 概念解释 单变量线性回归是最简单的线性回归形式，只使用一个特征（自变量）来预测目标值。\n特点 只有一个自变量（特征） 可以在二维平面上直观地表示为一条直线 适合研究两个变量之间的简单线性关系 应用场景 房价与面积的关系 销量与广告投入的关系 学习时间与考试成绩的关系 2.3 多变量线性回归 概念解释 多变量线性回归使用多个特征来预测目标值，是单变量线性回归的扩展。\n数学表达式 [ y = w_1x_1 + w_2x_2 + \u0026hellip; + w_nx_n + b ] 其中：\n( x_1, x_2, \u0026hellip;, x_n ) 是不同的特征 ( w_1, w_2, \u0026hellip;, w_n ) 是对应的权重 ( b ) 是偏置项 特点 考虑多个影响因素 可以捕捉更复杂的关系 在高维空间中形成超平面 应用场景 房价预测（面积、位置、楼层等多个因素） 销量预测（广告投入、季节、竞品价格等） 用户行为分析（年龄、收入、消费习惯等） 2.4 模型评估 线性回归模型的常用评估指标：\nR²分数（决定系数）\n范围：0~1 越接近1表示模型拟合越好 计算公式：[ R^2 = 1 - \\frac{\\sum(y - \\hat{y})^2}{\\sum(y - \\bar{y})^2} ] 均方误差（MSE）\n越小越好 计算公式：[ MSE = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 ] 平均绝对误差（MAE）\n越小越好 计算公式：[ MAE = \\frac{1}{n}\\sum_{i=1}^n|y_i - \\hat{y}_i| ] 2.5 实践示例 示例：房价 vs 面积 我们用一组简单的房价和面积数据，训练一个线性模型，预测房价。\n完整代码： import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression # 构造数据 area = np.array([30, 40, 50, 60, 70, 80]).reshape(-1, 1) price = np.array([100, 150, 200, 240, 280, 310]) # 建模 model = LinearRegression() model.fit(area, price) # 预测 area_pred = np.linspace(20, 100, 100).reshape(-1, 1) price_pred = model.predict(area_pred) # 可视化 plt.scatter(area, price, color=\u0026#39;blue\u0026#39;, label=\u0026#39;实际数据\u0026#39;) plt.plot(area_pred, price_pred, color=\u0026#39;red\u0026#39;, label=\u0026#39;预测线\u0026#39;) plt.xlabel(\u0026#39;面积（㎡）\u0026#39;) plt.ylabel(\u0026#39;房价（万元）\u0026#39;) plt.title(\u0026#39;房价 vs 面积（单变量线性回归）\u0026#39;) plt.legend() plt.grid(True) plt.show() 2.6 多变量线性回归示例 示例：房价 vs 面积 + 楼层 from sklearn.model_selection import train_test_split # 特征：面积、楼层 data = np.array([ [30, 2], [40, 3], [50, 5], [60, 6], [70, 8], [80, 9] ]) price = np.array([100, 140, 190, 230, 280, 320]) X_train, X_test, y_train, y_test = train_test_split( data, price, test_size=0.2, random_state=42 ) model = LinearRegression() model.fit(X_train, y_train) # 模型系数和截距 print(f\u0026#34;系数: {model.coef_}\u0026#34;) print(f\u0026#34;截距: {model.intercept_}\u0026#34;) # 预测 predictions = model.predict(X_test) print(f\u0026#34;预测值: {predictions}\u0026#34;) print(f\u0026#34;真实值: {y_test}\u0026#34;) 三、误差分析和特征权重分析 3.1 误差分析（残差分析） 概念解释 误差（残差） = 真实值 - 预测值 理想情况下，误差应当近似于正态分布，且均值为0 如果误差有明显偏移、模式，说明模型拟合不佳，可能需要换模型或加入更多特征 误差分析完整代码 import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split import seaborn as sns from sklearn.metrics import mean_squared_error # 构造示例数据 data = np.array([ [30, 2], [40, 3], [50, 5], [60, 6], [70, 8], [80, 9] ]) price = np.array([100, 140, 190, 230, 280, 320]) # 划分训练集和测试集 X_train, X_test, y_train, y_test = train_test_split( data, price, test_size=0.2, random_state=42 ) # 训练模型 model = LinearRegression() model.fit(X_train, y_train) # 预测和计算误差 predicted = model.predict(X_test) residuals = y_test - predicted # 绘制误差分布图 plt.figure(figsize=(10, 6)) sns.histplot(residuals, kde=True, bins=10, color=\u0026#39;purple\u0026#39;) plt.title(\u0026#39;预测误差分布图\u0026#39;) plt.xlabel(\u0026#39;预测误差（真实值 - 预测值）\u0026#39;) plt.ylabel(\u0026#39;频次\u0026#39;) plt.grid(True) plt.show() # 打印误差统计信息 print(f\u0026#34;平均误差: {np.mean(residuals):.2f}\u0026#34;) print(f\u0026#34;误差标准差: {np.std(residuals):.2f}\u0026#34;) print(f\u0026#34;均方误差(MSE): {mean_squared_error(y_test, predicted):.2f}\u0026#34;) 3.2 特征权重分析（系数） 概念解释 在线性模型中，每个特征的系数表示它对预测目标的\u0026quot;影响力\u0026quot; 系数越大（正负不重要），说明这个特征对预测结果越关键 可以用柱状图可视化权重大小 特征权重分析完整代码 import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split # 构造示例数据 data = np.array([ [30, 2], [40, 3], [50, 5], [60, 6], [70, 8], [80, 9] ]) price = np.array([100, 140, 190, 230, 280, 320]) # 训练模型 model = LinearRegression() model.fit(data, price) # 这里使用全部数据训练，因为我们只关注特征权重 # 准备数据 features = [\u0026#39;面积\u0026#39;, \u0026#39;楼层\u0026#39;] coefficients = model.coef_ # 创建特征权重可视化 plt.figure(figsize=(10, 6)) bars = plt.bar(features, coefficients, color=[\u0026#39;teal\u0026#39;, \u0026#39;coral\u0026#39;]) plt.title(\u0026#39;特征权重（回归系数）分析\u0026#39;) plt.ylabel(\u0026#39;权重大小\u0026#39;) plt.grid(True, axis=\u0026#39;y\u0026#39;) # 在柱状图上添加具体数值 for bar in bars: height = bar.get_height() plt.text(bar.get_x() + bar.get_width()/2., height, f\u0026#39;{height:.2f}\u0026#39;, ha=\u0026#39;center\u0026#39;, va=\u0026#39;bottom\u0026#39;) plt.show() # 打印特征权重信息 print(\u0026#34;特征权重分析:\u0026#34;) for feature, coef in zip(features, coefficients): print(f\u0026#34;{feature}: {coef:.2f}\u0026#34;) print(f\u0026#34;截距: {model.intercept_:.2f}\u0026#34;) 3.3 综合分析完整代码 如果你想同时进行误差分析和特征权重分析，可以使用下面的完整代码：\nimport numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split import seaborn as sns from sklearn.metrics import mean_squared_error # 构造示例数据 data = np.array([ [30, 2], [40, 3], [50, 5], [60, 6], [70, 8], [80, 9] ]) price = np.array([100, 140, 190, 230, 280, 320]) # 划分训练集和测试集 X_train, X_test, y_train, y_test = train_test_split( data, price, test_size=0.2, random_state=42 ) # 训练模型 model = LinearRegression() model.fit(X_train, y_train) # 1. 误差分析 predicted = model.predict(X_test) residuals = y_test - predicted # 创建子图 plt.figure(figsize=(15, 6)) # 误差分布图 plt.subplot(1, 2, 1) sns.histplot(residuals, kde=True, bins=10, color=\u0026#39;purple\u0026#39;) plt.title(\u0026#39;预测误差分布图\u0026#39;) plt.xlabel(\u0026#39;预测误差（真实值 - 预测值）\u0026#39;) plt.ylabel(\u0026#39;频次\u0026#39;) plt.grid(True) # 2. 特征权重分析 features = [\u0026#39;面积\u0026#39;, \u0026#39;楼层\u0026#39;] coefficients = model.coef_ plt.subplot(1, 2, 2) bars = plt.bar(features, coefficients, color=[\u0026#39;teal\u0026#39;, \u0026#39;coral\u0026#39;]) plt.title(\u0026#39;特征权重（回归系数）分析\u0026#39;) plt.ylabel(\u0026#39;权重大小\u0026#39;) plt.grid(True, axis=\u0026#39;y\u0026#39;) # 在柱状图上添加具体数值 for bar in bars: height = bar.get_height() plt.text(bar.get_x() + bar.get_width()/2., height, f\u0026#39;{height:.2f}\u0026#39;, ha=\u0026#39;center\u0026#39;, va=\u0026#39;bottom\u0026#39;) plt.tight_layout() plt.show() # 打印分析结果 print(\u0026#34;误差分析:\u0026#34;) print(f\u0026#34;平均误差: {np.mean(residuals):.2f}\u0026#34;) print(f\u0026#34;误差标准差: {np.std(residuals):.2f}\u0026#34;) print(f\u0026#34;均方误差(MSE): {mean_squared_error(y_test, predicted):.2f}\u0026#34;) print(\u0026#34;\\n特征权重分析:\u0026#34;) for feature, coef in zip(features, coefficients): print(f\u0026#34;{feature}: {coef:.2f}\u0026#34;) print(f\u0026#34;截距: {model.intercept_:.2f}\u0026#34;) 四、进阶探索 如果你想继续深入，可以探索以下主题：\n多项式回归：处理非线性关系 正则化方法： Ridge回归（L2正则化） Lasso回归（L1正则化） 模型评价指标： R²（决定系数） MSE（均方误差） MAE（平均绝对误差） 可视化分析： 残差图 预测-真实散点图 特征工程： 高阶特征构造 特征选择方法 参考资料 scikit-learn官方文档 Python数据科学手册 机器学习实战 注：本文代码基于Python 3.8+和scikit-learn 1.0+版本。\n","permalink":"https://xuyafei.github.io/personal-site/posts/regression/","summary":"\u003ch1 id=\"回归分析基础讲解与实战代码附图表展示\"\u003e回归分析基础讲解与实战代码（附图表展示）\u003c/h1\u003e\n\u003cp\u003e本文将详细讲解监督学习中的回归问题，特别是线性回归，包括其数学原理、编程实现以及如何通过图像分析模型表现，适合初学者快速入门，也适合有经验的开发者参考测试。\u003c/p\u003e\n\u003ch2 id=\"一什么是回归\"\u003e一、什么是回归？\u003c/h2\u003e\n\u003cp\u003e在监督学习中，\u003cstrong\u003e回归\u003c/strong\u003e是一种用于预测连续值的方法。\u003c/p\u003e\n\u003cp\u003e通俗地说，就是：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e给你一堆\u0026quot;输入-输出\u0026quot;的样本数据，让你学习出一个数学表达式，这个表达式能用来预测新数据的输出。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e就像一句比喻：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;给出了一堆数据和结果，然后推导出一个公式\u0026rdquo;——这就是回归的核心本质。\u003c/p\u003e\u003c/blockquote\u003e\n\u003ch2 id=\"二线性回归模型单变量与多变量\"\u003e二、线性回归模型：单变量与多变量\u003c/h2\u003e\n\u003ch3 id=\"21-线性回归的基本概念\"\u003e2.1 线性回归的基本概念\u003c/h3\u003e\n\u003cp\u003e线性回归是最基础也是最常用的回归分析方法。它通过建立因变量（预测目标）与自变量（特征）之间的线性关系来进行预测。\u003c/p\u003e\n\u003ch4 id=\"数学表达式\"\u003e数学表达式\u003c/h4\u003e\n\u003cp\u003e线性回归的基本形式是：\n[ y = wx + b ]\n其中：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e( y ) 是预测值（因变量）\u003c/li\u003e\n\u003cli\u003e( x ) 是特征（自变量）\u003c/li\u003e\n\u003cli\u003e( w ) 是权重（斜率）\u003c/li\u003e\n\u003cli\u003e( b ) 是偏置项（截距）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"模型目标\"\u003e模型目标\u003c/h4\u003e\n\u003cp\u003e线性回归的目标是找到最优的 ( w ) 和 ( b )，使得预测值与真实值之间的误差最小。通常使用均方误差（MSE）作为优化目标：\n[ MSE = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 ]\n其中 ( y_i ) 是真实值，( \\hat{y}_i ) 是预测值。\u003c/p\u003e\n\u003ch3 id=\"22-单变量线性回归\"\u003e2.2 单变量线性回归\u003c/h3\u003e\n\u003ch4 id=\"概念解释\"\u003e概念解释\u003c/h4\u003e\n\u003cp\u003e单变量线性回归是最简单的线性回归形式，只使用一个特征（自变量）来预测目标值。\u003c/p\u003e\n\u003ch4 id=\"特点\"\u003e特点\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e只有一个自变量（特征）\u003c/li\u003e\n\u003cli\u003e可以在二维平面上直观地表示为一条直线\u003c/li\u003e\n\u003cli\u003e适合研究两个变量之间的简单线性关系\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"应用场景\"\u003e应用场景\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e房价与面积的关系\u003c/li\u003e\n\u003cli\u003e销量与广告投入的关系\u003c/li\u003e\n\u003cli\u003e学习时间与考试成绩的关系\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"23-多变量线性回归\"\u003e2.3 多变量线性回归\u003c/h3\u003e\n\u003ch4 id=\"概念解释-1\"\u003e概念解释\u003c/h4\u003e\n\u003cp\u003e多变量线性回归使用多个特征来预测目标值，是单变量线性回归的扩展。\u003c/p\u003e","title":"回归分析基础讲解与实战代码（附图表展示）"},{"content":"引言 C++ 的引用机制是该语言最强大且独特的特性之一。它不仅提供了一种安全的指针替代方案，还是现代 C++ 中移动语义和完美转发等高级特性的基础。本文将深入探讨 C++ 引用机制的各个方面，从基础概念到高级应用。\n引用的基本概念 什么是引用？ 引用可以看作是一个变量的别名。它在内存中不占用额外空间（在大多数实现中），必须在创建时初始化，并且一旦绑定到一个变量，就不能再引用其他变量。\nint x = 42; int\u0026amp; ref = x; // ref 是 x 的引用 ref = 24; // 修改 ref 就是修改 x 引用 vs 指针 引用和指针有一些重要的区别：\n初始化要求：\nint* ptr; // 合法，可以不初始化 int\u0026amp; ref; // 非法，引用必须初始化 重新赋值：\nint x = 1, y = 2; int* ptr = \u0026amp;x; ptr = \u0026amp;y; // 合法，指针可以指向新的地址 int\u0026amp; ref = x; ref = y; // 这是赋值操作，不是重新引用 空值：\nint* ptr = nullptr; // 合法 int\u0026amp; ref = nullptr; // 非法，引用不能为空 引用的类型 1. 左值引用 最基本的引用类型，用于引用可以取地址的表达式：\nint x = 42; int\u0026amp; ref = x; // 左值引用 // 不能引用字面量 int\u0026amp; ref2 = 42; // 错误！不能引用右值 2. 常量引用 可以引用常量，也可以引用右值：\nconst int\u0026amp; ref = 42; // 合法，可以引用右值 int x = 42; const int\u0026amp; ref2 = x; // 可以引用非常量 3. 右值引用 C++11 引入的新特性，用于支持移动语义：\nint\u0026amp;\u0026amp; rref = 42; // 右值引用 int x = 42; int\u0026amp;\u0026amp; rref2 = x; // 错误！不能绑定到左值 int\u0026amp;\u0026amp; rref3 = std::move(x); // 正确，std::move 将左值转换为右值 引用的常见应用场景 1. 函数参数 // 传值 void byValue(int x) { x = 42; // 不影响原始值 } // 引用传递 void byReference(int\u0026amp; x) { x = 42; // 修改原始值 } // 常量引用，用于大对象 void byConstReference(const std::string\u0026amp; str) { std::cout \u0026lt;\u0026lt; str; // 只读访问，避免拷贝 } 2. 函数返回值 // 返回引用 int\u0026amp; getElement(std::vector\u0026lt;int\u0026gt;\u0026amp; vec, size_t index) { return vec[index]; // 可以修改原始元素 } // 返回常量引用 const std::string\u0026amp; getString() { static std::string str = \u0026#34;Hello\u0026#34;; return str; // 返回静态对象的引用 } 3. 范围 for 循环 std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3, 4, 5}; // 只读访问 for (const int\u0026amp; x : vec) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } // 修改元素 for (int\u0026amp; x : vec) { x *= 2; } 高级应用 1. 完美转发 使用模板和通用引用（universal reference）实现参数完美转发：\ntemplate\u0026lt;typename T\u0026gt; void wrapper(T\u0026amp;\u0026amp; arg) { // 完美转发参数 foo(std::forward\u0026lt;T\u0026gt;(arg)); } 2. 移动语义 使用右值引用实现高效的资源转移：\nclass MyString { public: // 移动构造函数 MyString(MyString\u0026amp;\u0026amp; other) noexcept { data_ = other.data_; other.data_ = nullptr; } private: char* data_; }; 3. 引用折叠 理解引用折叠规则对于模板编程很重要：\ntemplate\u0026lt;typename T\u0026gt; void foo(T\u0026amp;\u0026amp; x) { // 通用引用 // T\u0026amp; \u0026amp; 折叠为 T\u0026amp; // T\u0026amp; \u0026amp;\u0026amp; 折叠为 T\u0026amp; // T\u0026amp;\u0026amp; \u0026amp; 折叠为 T\u0026amp; // T\u0026amp;\u0026amp; \u0026amp;\u0026amp; 折叠为 T\u0026amp;\u0026amp; } 最佳实践 使用常量引用传递大对象：\nvoid process(const BigObject\u0026amp; obj); // 比传值效率高 避免返回局部变量的引用：\nint\u0026amp; bad() { int x = 42; return x; // 危险！返回局部变量的引用 } 使用右值引用实现移动语义：\nclass MyClass { MyClass(MyClass\u0026amp;\u0026amp; other) noexcept; // 移动构造函数 MyClass\u0026amp; operator=(MyClass\u0026amp;\u0026amp; other) noexcept; // 移动赋值运算符 }; 使用 std::ref 在需要时创建引用包装器：\nvoid foo(int\u0026amp; x); int x = 42; std::thread t(foo, std::ref(x)); // 传递引用给线程 注意事项 不要返回局部变量的引用 确保引用的对象生命周期足够长 使用常量引用来防止意外修改 理解右值引用和移动语义的关系 注意引用折叠规则在模板中的应用 总结 C++ 的引用机制是一个强大的特性，它不仅提供了一种安全的指针替代方案，还是现代 C++ 中许多高级特性的基础。通过合理使用不同类型的引用，我们可以编写出更高效、更安全的代码。\n理解引用机制对于掌握 C++ 至关重要，它不仅涉及基本的语言特性，还与移动语义、完美转发等现代 C++ 特性密切相关。在实际编程中，合理使用引用可以显著提高代码的性能和可维护性。\n参考资料 C++ 标准文档 Effective Modern C++ (Scott Meyers) C++ Templates: The Complete Guide ","permalink":"https://xuyafei.github.io/personal-site/posts/cpp-references/","summary":"\u003ch2 id=\"引言\"\u003e引言\u003c/h2\u003e\n\u003cp\u003eC++ 的引用机制是该语言最强大且独特的特性之一。它不仅提供了一种安全的指针替代方案，还是现代 C++ 中移动语义和完美转发等高级特性的基础。本文将深入探讨 C++ 引用机制的各个方面，从基础概念到高级应用。\u003c/p\u003e\n\u003ch2 id=\"引用的基本概念\"\u003e引用的基本概念\u003c/h2\u003e\n\u003ch3 id=\"什么是引用\"\u003e什么是引用？\u003c/h3\u003e\n\u003cp\u003e引用可以看作是一个变量的别名。它在内存中不占用额外空间（在大多数实现中），必须在创建时初始化，并且一旦绑定到一个变量，就不能再引用其他变量。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e ref \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e x;  \u003cspan style=\"color:#75715e\"\u003e// ref 是 x 的引用\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003eref \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e24\u003c/span\u003e;      \u003cspan style=\"color:#75715e\"\u003e// 修改 ref 就是修改 x\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"引用-vs-指针\"\u003e引用 vs 指针\u003c/h3\u003e\n\u003cp\u003e引用和指针有一些重要的区别：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e初始化要求\u003c/strong\u003e：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e ptr;     \u003cspan style=\"color:#75715e\"\u003e// 合法，可以不初始化\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e ref;     \u003cspan style=\"color:#75715e\"\u003e// 非法，引用必须初始化\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e重新赋值\u003c/strong\u003e：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e, y \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e ptr \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003ex;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eptr \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003ey;      \u003cspan style=\"color:#75715e\"\u003e// 合法，指针可以指向新的地址\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e ref \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e x;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eref \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e y;       \u003cspan style=\"color:#75715e\"\u003e// 这是赋值操作，不是重新引用\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e空值\u003c/strong\u003e：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e ptr \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enullptr\u003c/span\u003e;  \u003cspan style=\"color:#75715e\"\u003e// 合法\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e ref \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enullptr\u003c/span\u003e;  \u003cspan style=\"color:#75715e\"\u003e// 非法，引用不能为空\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"引用的类型\"\u003e引用的类型\u003c/h2\u003e\n\u003ch3 id=\"1-左值引用\"\u003e1. 左值引用\u003c/h3\u003e\n\u003cp\u003e最基本的引用类型，用于引用可以取地址的表达式：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e x \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e ref \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e x;  \u003cspan style=\"color:#75715e\"\u003e// 左值引用\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// 不能引用字面量\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e ref2 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e;  \u003cspan style=\"color:#75715e\"\u003e// 错误！不能引用右值\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"2-常量引用\"\u003e2. 常量引用\u003c/h3\u003e\n\u003cp\u003e可以引用常量，也可以引用右值：\u003c/p\u003e","title":"C++ 引用详解：从基础到高级应用"},{"content":"1. 偏导数（Partial Derivative） 定义 偏导数是多元函数对某一个自变量的导数，表示当其他自变量固定时，函数沿该方向的变化率。\n通俗解释 想象你站在一个山坡上（函数 $f(x,y)$ 表示海拔）：\n对 $x$ 的偏导数（$\\frac{\\partial f}{\\partial x}$）是仅沿东西方向移动时的坡度。 对 $y$ 的偏导数（$\\frac{\\partial f}{\\partial y}$）是仅沿南北方向的坡度。 数学形式 对于函数 $f(x_1, x_2, \\dots, x_n)$：\n$$ \\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, \\dots, x_i + h, \\dots, x_n) - f(x_1, \\dots, x_n)}{h} $$\n例子 设 $f(x,y) = x^2 + 3xy$：\n$\\frac{\\partial f}{\\partial x} = 2x + 3y$ （视 $y$ 为常数） $\\frac{\\partial f}{\\partial y} = 3x$ （视 $x$ 为常数） 2. 梯度（Gradient） 定义 梯度是一个向量，由函数在所有自变量上的偏导数组成，指向函数值增长最快的方向。\n通俗解释 梯度是山坡上\u0026quot;最陡的上坡方向\u0026quot;。 梯度的大小表示该方向的陡峭程度。 数学形式 对于 $f(x_1, x_2, \\dots, x_n)$，梯度记作 $\\nabla f$：\n$$ \\nabla f = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n} \\right) $$\n例子 继续用 $f(x,y) = x^2 + 3xy$：\n$$ \\nabla f = \\left( 2x + 3y, 3x \\right) $$\n在点 $(1, 2)$ 处的梯度为 $\\nabla f = (8, 3)$，表示从该点出发，沿方向 $(8, 3)$ 函数值增长最快。\n3. 关键点总结 偏导数：单一方向的变化率，其他变量固定。 梯度： 是所有偏导数的向量组合。 方向指向函数值最大增长方向。 在优化中，负梯度方向是函数值下降最快的方向。 4. 几何意义 梯度方向：函数增长最快的方向。 梯度大小：变化率的强度（越陡峭，梯度越大）。 等高线：梯度与等高线垂直。 5. 应用场景 机器学习：梯度下降法通过沿负梯度方向更新参数。 物理学：电势的梯度是电场强度。 工程优化：寻找多维函数的最优解。 注：本文使用 MathJax 渲染数学公式，确保最佳显示效果。\n","permalink":"https://xuyafei.github.io/personal-site/posts/partial-derivatives-and-gradients/","summary":"\u003ch2 id=\"1-偏导数partial-derivative\"\u003e1. 偏导数（Partial Derivative）\u003c/h2\u003e\n\u003ch3 id=\"定义\"\u003e定义\u003c/h3\u003e\n\u003cp\u003e偏导数是多元函数对\u003cstrong\u003e某一个自变量\u003c/strong\u003e的导数，表示当其他自变量固定时，函数沿该方向的变化率。\u003c/p\u003e\n\u003ch3 id=\"通俗解释\"\u003e通俗解释\u003c/h3\u003e\n\u003cp\u003e想象你站在一个山坡上（函数 $f(x,y)$ 表示海拔）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e对 $x$ 的偏导数（$\\frac{\\partial f}{\\partial x}$）是\u003cstrong\u003e仅沿东西方向\u003c/strong\u003e移动时的坡度。\u003c/li\u003e\n\u003cli\u003e对 $y$ 的偏导数（$\\frac{\\partial f}{\\partial y}$）是\u003cstrong\u003e仅沿南北方向\u003c/strong\u003e的坡度。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"数学形式\"\u003e数学形式\u003c/h3\u003e\n\u003cp\u003e对于函数 $f(x_1, x_2, \\dots, x_n)$：\u003c/p\u003e\n\u003cp\u003e$$\n\\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, \\dots, x_i + h, \\dots, x_n) - f(x_1, \\dots, x_n)}{h}\n$$\u003c/p\u003e\n\u003ch3 id=\"例子\"\u003e例子\u003c/h3\u003e\n\u003cp\u003e设 $f(x,y) = x^2 + 3xy$：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$\\frac{\\partial f}{\\partial x} = 2x + 3y$ （视 $y$ 为常数）\u003c/li\u003e\n\u003cli\u003e$\\frac{\\partial f}{\\partial y} = 3x$ （视 $x$ 为常数）\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-梯度gradient\"\u003e2. 梯度（Gradient）\u003c/h2\u003e\n\u003ch3 id=\"定义-1\"\u003e定义\u003c/h3\u003e\n\u003cp\u003e梯度是一个向量，由函数在所有自变量上的偏导数组成，指向函数值\u003cstrong\u003e增长最快\u003c/strong\u003e的方向。\u003c/p\u003e","title":"偏导数与梯度的概念详解"},{"content":"这是一个测试页面，包含行内公式和块级公式。\n✅ 行内公式示例： 牛顿第二定律：$F = ma$，这个公式描述了力和加速度的关系。\n✅ 块级公式示例： 下面是偏导数的定义：\n$$ \\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, \\dots, x_i + h, \\dots, x_n) - f(x_1, \\dots, x_n)}{h} $$\n","permalink":"https://xuyafei.github.io/personal-site/posts/katex-test/","summary":"\u003cp\u003e这是一个测试页面，包含行内公式和块级公式。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-行内公式示例\"\u003e✅ 行内公式示例：\u003c/h3\u003e\n\u003cp\u003e牛顿第二定律：$F = ma$，这个公式描述了力和加速度的关系。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-块级公式示例\"\u003e✅ 块级公式示例：\u003c/h3\u003e\n\u003cp\u003e下面是偏导数的定义：\u003c/p\u003e\n\u003cp\u003e$$\n\\frac{\\partial f}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, \\dots, x_i + h, \\dots, x_n) - f(x_1, \\dots, x_n)}{h}\n$$\u003c/p\u003e","title":"KaTeX 测试"},{"content":"本文用于测试在 Hugo 博客中引用 static/images/ 目录下的图片资源。\n🖼️ 1. Confusion Matrix (Digits) 🖼️ 2. Iris 分类图 🖼️ 3. 神经网络分类图 🖼️ 4. 多项式分类边界图（注意拼写错误） ⚠️ 文件名是 polynomical_calssification.png，注意不是 polynomial / classification。\n🖼️ 5. SVM 分类图 如你所见，只要将图片放入 static/images/ 目录，并在文章中用 /images/xxx.png 的方式引用即可完成图像展示。\n","permalink":"https://xuyafei.github.io/personal-site/posts/test-images/","summary":"\u003cp\u003e本文用于测试在 Hugo 博客中引用 \u003ccode\u003estatic/images/\u003c/code\u003e 目录下的图片资源。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-1-confusion-matrix-digits\"\u003e🖼️ 1. Confusion Matrix (Digits)\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"Confusion Matrix\" loading=\"lazy\" src=\"/personal-site/posts/test-images/confusion_matrix_digits.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-2-iris-分类图\"\u003e🖼️ 2. Iris 分类图\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"Iris 分类\" loading=\"lazy\" src=\"/personal-site/posts/test-images/iris_classification.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-3-神经网络分类图\"\u003e🖼️ 3. 神经网络分类图\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"神经网络分类\" loading=\"lazy\" src=\"/personal-site/posts/test-images/nn_classification.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-4-多项式分类边界图注意拼写错误\"\u003e🖼️ 4. 多项式分类边界图（注意拼写错误）\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ 文件名是 \u003ccode\u003epolynomical_calssification.png\u003c/code\u003e，注意不是 polynomial / classification。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"多项式分类\" loading=\"lazy\" src=\"/personal-site/posts/test-images/polynomical_calssification.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"-5-svm-分类图\"\u003e🖼️ 5. SVM 分类图\u003c/h3\u003e\n\u003cp\u003e\u003cimg alt=\"SVM 分类\" loading=\"lazy\" src=\"/personal-site/posts/test-images/svm_classification.png\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e如你所见，只要将图片放入 \u003ccode\u003estatic/images/\u003c/code\u003e 目录，并在文章中用 \u003ccode\u003e/images/xxx.png\u003c/code\u003e 的方式引用即可完成图像展示。\u003c/p\u003e","title":"测试图片引用"},{"content":"图片显示测试 这是一篇测试文章，用于验证图片是否能正确显示。\n测试图片1：鸢尾花分类结果 测试图片2：混淆矩阵 测试图片3：多项式特征分类 测试图片4：SVM分类 测试图片5：神经网络分类 测试结果 如果上面的图片都能正确显示，说明图片路径和引用方式是正确的。如果有些图片无法显示，可能需要检查：\n图片文件是否已正确上传到 /static/images/ 目录 图片文件名是否与引用中的名称完全匹配（包括大小写） 图片路径是否正确（应该是 /images/ 开头） ","permalink":"https://xuyafei.github.io/personal-site/posts/image-test/","summary":"\u003ch1 id=\"图片显示测试\"\u003e图片显示测试\u003c/h1\u003e\n\u003cp\u003e这是一篇测试文章，用于验证图片是否能正确显示。\u003c/p\u003e\n\u003ch2 id=\"测试图片1鸢尾花分类结果\"\u003e测试图片1：鸢尾花分类结果\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"鸢尾花分类结果\" loading=\"lazy\" src=\"/personal-site/posts/image-test/iris_classification.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"测试图片2混淆矩阵\"\u003e测试图片2：混淆矩阵\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"混淆矩阵\" loading=\"lazy\" src=\"/personal-site/posts/image-test/confusion_matrix_digits.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"测试图片3多项式特征分类\"\u003e测试图片3：多项式特征分类\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"多项式特征分类\" loading=\"lazy\" src=\"/personal-site/posts/image-test/polynomical_calssification.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"测试图片4svm分类\"\u003e测试图片4：SVM分类\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"SVM分类\" loading=\"lazy\" src=\"/personal-site/posts/image-test/svm_classification.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"测试图片5神经网络分类\"\u003e测试图片5：神经网络分类\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"神经网络分类\" loading=\"lazy\" src=\"/personal-site/posts/image-test/nn_classification.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"测试结果\"\u003e测试结果\u003c/h2\u003e\n\u003cp\u003e如果上面的图片都能正确显示，说明图片路径和引用方式是正确的。如果有些图片无法显示，可能需要检查：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e图片文件是否已正确上传到 \u003ccode\u003e/static/images/\u003c/code\u003e 目录\u003c/li\u003e\n\u003cli\u003e图片文件名是否与引用中的名称完全匹配（包括大小写）\u003c/li\u003e\n\u003cli\u003e图片路径是否正确（应该是 \u003ccode\u003e/images/\u003c/code\u003e 开头）\u003c/li\u003e\n\u003c/ol\u003e","title":"图片显示测试"},{"content":"baseURL = \u0026lsquo;https://example.org/' languageCode = \u0026lsquo;zh-cn\u0026rsquo; title = \u0026lsquo;我的博客\u0026rsquo; theme = \u0026lsquo;PaperMod\u0026rsquo;\nPaperMod 主题的基本配置 [params] defaultTheme = \u0026ldquo;auto\u0026rdquo; ShowReadingTime = true ShowShareButtons = true ShowPostNavLinks = true ShowBreadCrumbs = true ShowCodeCopyButtons = true ShowRssButtonInSectionTermList = true ShowToc = true\n[params.homeInfoParams] Title = \u0026ldquo;欢迎来到我的博客 👋\u0026rdquo; Content = \u0026ldquo;这里是我的个人博客，我会在这里分享一些想法和经验。\u0026rdquo;\n[params.profileMode] enabled = false\n[menu] main = [ {identifier = \u0026ldquo;categories\u0026rdquo;, name = \u0026ldquo;分类\u0026rdquo;, url = \u0026ldquo;/categories/\u0026rdquo;, weight = 10}, {identifier = \u0026ldquo;tags\u0026rdquo;, name = \u0026ldquo;标签\u0026rdquo;, url = \u0026ldquo;/tags/\u0026rdquo;, weight = 20}, {identifier = \u0026ldquo;archives\u0026rdquo;, name = \u0026ldquo;归档\u0026rdquo;, url = \u0026ldquo;/archives/\u0026rdquo;, weight = 30}, {identifier = \u0026ldquo;search\u0026rdquo;, name = \u0026ldquo;搜索\u0026rdquo;, url = \u0026ldquo;/search/\u0026rdquo;, weight = 40}, ]\n启用搜索功能 [outputs] home = [ \u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;RSS\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo; ]\n","permalink":"https://xuyafei.github.io/personal-site/posts/my-first-post/","summary":"\u003cp\u003ebaseURL = \u0026lsquo;\u003ca href=\"https://example.org/'\"\u003ehttps://example.org/'\u003c/a\u003e\nlanguageCode = \u0026lsquo;zh-cn\u0026rsquo;\ntitle = \u0026lsquo;我的博客\u0026rsquo;\ntheme = \u0026lsquo;PaperMod\u0026rsquo;\u003c/p\u003e\n\u003ch1 id=\"papermod-主题的基本配置\"\u003ePaperMod 主题的基本配置\u003c/h1\u003e\n\u003cp\u003e[params]\ndefaultTheme = \u0026ldquo;auto\u0026rdquo;\nShowReadingTime = true\nShowShareButtons = true\nShowPostNavLinks = true\nShowBreadCrumbs = true\nShowCodeCopyButtons = true\nShowRssButtonInSectionTermList = true\nShowToc = true\u003c/p\u003e\n\u003cp\u003e[params.homeInfoParams]\nTitle = \u0026ldquo;欢迎来到我的博客 👋\u0026rdquo;\nContent = \u0026ldquo;这里是我的个人博客，我会在这里分享一些想法和经验。\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e[params.profileMode]\nenabled = false\u003c/p\u003e\n\u003cp\u003e[menu]\nmain = [\n{identifier = \u0026ldquo;categories\u0026rdquo;, name = \u0026ldquo;分类\u0026rdquo;, url = \u0026ldquo;/categories/\u0026rdquo;, weight = 10},\n{identifier = \u0026ldquo;tags\u0026rdquo;, name = \u0026ldquo;标签\u0026rdquo;, url = \u0026ldquo;/tags/\u0026rdquo;, weight = 20},\n{identifier = \u0026ldquo;archives\u0026rdquo;, name = \u0026ldquo;归档\u0026rdquo;, url = \u0026ldquo;/archives/\u0026rdquo;, weight = 30},\n{identifier = \u0026ldquo;search\u0026rdquo;, name = \u0026ldquo;搜索\u0026rdquo;, url = \u0026ldquo;/search/\u0026rdquo;, weight = 40},\n]\u003c/p\u003e","title":""}]
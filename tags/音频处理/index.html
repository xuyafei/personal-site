<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>音频处理 | 我的博客</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://xuyafei.github.io/personal-site/tags/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/><link crossorigin=anonymous href=/personal-site/assets/css/stylesheet.93f625d739f1d6a5c6f20c146bc6a8d26b233492b34b2220c54b12fd46a04ded.css integrity="sha256-k/Yl1znx1qXG8gwUa8ao0msjNJKzSyIgxUsS/UagTe0=" rel="preload stylesheet" as=style><link rel=icon href=https://xuyafei.github.io/personal-site/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://xuyafei.github.io/personal-site/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://xuyafei.github.io/personal-site/favicon-32x32.png><link rel=apple-touch-icon href=https://xuyafei.github.io/personal-site/apple-touch-icon.png><link rel=mask-icon href=https://xuyafei.github.io/personal-site/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://xuyafei.github.io/personal-site/tags/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/index.xml><link rel=alternate hreflang=en href=https://xuyafei.github.io/personal-site/tags/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAYQHy+K8nqKdr1EzvFzSQC+TAXx6gNQgoRxKtj+P9vvCCQTRWiV crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><script>MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta property="og:url" content="https://xuyafei.github.io/personal-site/tags/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/"><meta property="og:site_name" content="我的博客"><meta property="og:title" content="音频处理"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="音频处理"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xuyafei.github.io/personal-site/ accesskey=h title="我的博客 (Alt + H)">我的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://xuyafei.github.io/personal-site/categories/ title=分类><span>分类</span></a></li><li><a href=https://xuyafei.github.io/personal-site/tags/ title=标签><span>标签</span></a></li><li><a href=https://xuyafei.github.io/personal-site/archives/ title=归档><span>归档</span></a></li><li><a href=https://xuyafei.github.io/personal-site/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://xuyafei.github.io/personal-site/>Home</a>&nbsp;»&nbsp;<a href=https://xuyafei.github.io/personal-site/tags/>标签</a></div><h1>音频处理
<a href=/personal-site/tags/%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>AEC回声消除技术详解</h2></header><div class=entry-content><p>什么是 AEC？ AEC 是用于消除扬声器声音被麦克风"再次拾取"造成的回音现象的技术。 常见于以下场景：
A 在说话，声音通过扬声器播出 A 的麦克风也拾取了扬声器的声音 B 就会听到 A 的声音+回音（自己的声音回传） AEC 的基本原理 AEC 的核心思想是：提前预估扬声器播放的信号，并从麦克风信号中消除掉这部分"预测声波"。
麦克风信号 = 本地人声 + 扬声器声音（回声） AEC目标 = 从中消除"扬声器声音"部分
AEC 一般由两路信号输入：
Near-end（近端）信号：麦克风采集到的原始信号（含人声 + 回音） Far-end（远端）信号：扬声器播放的信号（即收到远端传过来的音频） AEC 会使用一个自适应滤波器来构建 Far-end 到 Near-end 的"回声路径"，然后将估计得到的回声从 Near-end 信号中减去。
AEC 的处理流程 +-----------+ +----------------+ +--------------+ | Far-end | | Adaptive Echo | | Subtract | | Signal +------->+ Estimation +------>+ Echo +----> Clean Near-End | | | (Filter) | | Signal | +-----------+ +----------------+ +--------------+ ▲ | Feedback Loop (更新滤波器) 处理步骤：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to AEC回声消除技术详解" href=https://xuyafei.github.io/personal-site/posts/aec/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>音频系统中的非线性失真补偿技术详解</h2></header><div class=entry-content><p>非线性失真补偿技术概述 非线性失真补偿技术（nonlinear distortion compensation）主要用于在音频通信或音频处理系统中，修正由于放大器、扬声器、ADC/DAC 等系统部件引入的非线性畸变。这类失真在高质量语音通话、AEC（回声消除）、降噪、回放增强等领域非常关键。
什么是非线性失真？ 线性系统 满足两个条件：
齐次性：输入加倍，输出也加倍（如 y = 2x → 2y = 2·2x） 叠加性：两个输入信号的响应等于各自响应之和（如 A + B → 输出A + 输出B） 非线性失真 当系统违反这两个原则时就发生非线性，例如：
放大器过载（削波 Clipping） 扬声器磁饱和、谐波产生 数字信号压缩编码（Companding） D/A 或 A/D 分辨率太低 常见非线性失真类型 类型 表现形式 削波（Clipping） 输入过大被强行"截断" 谐波失真 多出原频率整数倍的频率成分 交调失真 多个频率信号相互干扰，产生额外频率 动态压缩失真 某些频率范围失真更严重 为什么 AEC/降噪时要考虑非线性失真？ 问题 AEC 使用自适应滤波器估计回声路径，但这个滤波器默认是线性的 FIR 滤波器，如果回声路径（如扬声器）存在非线性行为（如削波、失真），那你无法用线性滤波器准确估计它 → 导致残留回声。
非线性失真补偿技术分类 1. 预失真（Pre-Distortion）技术 原理：在信号送入非线性系统（如功放）前，先对其"预处理"一下，反向建模非线性，从而抵消即将发生的畸变。 应用：音频播放、无线通信前端 2. Volterra 滤波器 一种能建模非线性系统的高级滤波器（包含多阶项，如二阶、三阶互作用） 比传统 FIR 滤波器更复杂，但能表达非线性响应 y(n) = Σ h1[i]·x(n−i) + ΣΣ h2[i][j]·x(n−i)·x(n−j) + ... 3. 基于机器学习的建模 使用 DNN、LSTM、Transformers 等网络学习非线性映射关系 适合对"系统输出"和"干净目标"建模残差，进行非线性补偿 4. 非线性回声消除（NLAEC） 针对回声路径为非线性的场景，如手机扬声器压缩、蓝牙耳机饱和等 会联合使用： 多通道滤波器组 非线性特征提取（如平方、对数、激活函数） 自适应更新策略（NLMS+VAF、RLS变体） 应用中的策略示例 AEC 中的增强路径建模（LMS 估计基础上加入非线性残差估计） RNNoise / DeepFilterNet 之类的系统中，加入 DNN 估计非线性失真分量并减去 听觉模型补偿（加入感知失真度量，结合人耳模型做修正） WebRTC 中的非线性失真处理 背景：WebRTC 中非线性失真的本质 WebRTC 的 AEC 假设系统是线性的，即使用 NLMS 或 Frequency-domain LMS 去估计回声路径。但实际设备中的扬声器/功放常存在削波、饱和等现象，导致：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 音频系统中的非线性失真补偿技术详解" href=https://xuyafei.github.io/personal-site/posts/nonlinear_distortion_compensation/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>WebRTC AEC 与 RNNoise 组合：增强回声消除效果的技术方案</h2></header><div class=entry-content><p>WebRTC AEC 与 RNNoise 组合方案概述 在实时音频通信中，回声消除（AEC）是一个关键挑战。虽然 WebRTC 的 AEC3 模块能够有效处理线性回声，但在面对非线性失真、残留回声和背景噪声混杂等复杂场景时，其效果仍有提升空间。本文将详细介绍如何将 RNNoise（一个轻量级 RNN 神经网络模型）与 WebRTC AEC3 结合使用，以进一步提升回声消除效果。
核心思想 WebRTC AEC3 负责建模回声路径并估计线性回声，而 RNNoise 作为后处理器，对 AEC 输出进行进一步增强和净化。这种组合方案能够有效处理：
非线性残留回声 噪声混合回声 误判人声回声 系统架构 处理流程 远端音频 → WebRTC AEC3 → (回声估计并相减) ↓ AEC 输出（含残留） → RNNoise → 输出净化音频 → 编码 Opus 模块职责对比 模块 功能 优势 局限性 WebRTC AEC3 建模线性回声路径（FIR）、频域增益压制 轻量、低延迟 残留回声较多 RNNoise 用 RNN 预测并抑制噪声与非线性残留 对低频残留、远端残渣处理效果好 训练集受限 为什么需要 RNNoise？ WebRTC AEC 模块在处理以下情况时存在局限性：
音量过大导致的削波非线性 滤波器建模误差（路径太长） NLP 误判人声为回声而抑制失败 多源混合导致时延估计漂移 RNNoise 作为频谱增强器，能够：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to WebRTC AEC 与 RNNoise 组合：增强回声消除效果的技术方案" href=https://xuyafei.github.io/personal-site/posts/webrtc_aec_rnnoise/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>语音活动检测（VAD）技术详解</h2></header><div class=entry-content><p>语音活动检测（VAD）概述 语音活动检测（Voice Activity Detection，VAD）是音频信号处理中的基础模块，用于判断一段音频中是否包含人声。它在实时语音通信、语音识别、音频处理等领域发挥着重要作用。
VAD 的主要应用场景 1. 消除静音段，降低带宽和计算资源消耗 在 VoIP 等实时语音通信中，VAD 可以：
停止静音段的音频编码与发送 丢弃静音包或减少帧率 暂停对静音段的播放 发送 Comfort Noise（舒适噪声）包替代静音数据 2. 配合音频处理模块使用 VAD 可以与以下模块协同工作：
回声消除（AEC）：防止在静音时更新错误的回声模型 噪声抑制（NS）：帮助区分"语音+噪声"与"纯噪声" 自动增益控制（AGC）：防止对静音或噪声进行放大 3. 触发语音识别（ASR）引擎 VAD 可用于：
检测语音开始，启动语音识别引擎 检测语音结束，终止识别并提交结果 控制"有声录音"功能 4. 优化语音通信 在视频会议等场景中：
静音压缩（silence compression） 发送 CN（Comfort Noise）包 减少传输帧率 VAD 的基本原理 特征提取 VAD 通常基于以下特征进行判断：
短时能量（Short-Time Energy） E = \sum_{n=0}^{N-1} x[n]^2 过零率（Zero-Crossing Rate, ZCR） \text{ZCR} = \frac{1}{2N} \sum_{n=1}^{N} | \text{sgn}(x[n]) - \text{sgn}(x[n-1]) | 谱熵（Spectral Entropy） 衡量信号频谱的"有序性" 语音谱结构复杂，熵值较高 短时谱幅度 语音的频谱幅度分布与噪声不同 VAD 的类型 基于规则的传统 VAD
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 语音活动检测（VAD）技术详解" href=https://xuyafei.github.io/personal-site/posts/voice_activity_detection/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Opus音频编解码器详解</h2></header><div class=entry-content><p>Opus音频编解码器详解 一、什么是Opus？ Opus是一种专为实时音频通信设计的开放、免版权费的音频编解码器，由IETF标准化（RFC 6716）。
主要优势 低延迟（最小5ms） 高音质（语音、音乐都很优秀） 自适应码率、采样率、帧长 适合语音和全频音乐（宽频甚至超宽频） 广泛应用于WebRTC、Zoom、Discord、Google Meet、Skype等 二、Opus的核心特性 特性 说明 支持采样率 8kHz ～ 48kHz 支持声道 单声道（mono）、立体声（stereo） 支持码率 6kbps ～ 510kbps（可变/恒定） 支持帧长 2.5ms、5ms、10ms、20ms、40ms、60ms 自适应编码模式 SILK（语音）、CELT（音乐）、混合模式（语音中带音乐） 可封装格式 Ogg、WebM、RTP 三、Opus是如何工作的？ Opus融合了两种技术，根据内容自动选择编码方式：
模块 用于 描述 SILK 语音 来自Skype，适合低码率、人声编码 CELT 音乐 基于MDCT的宽频音频压缩，适合音乐和高保真音频 混合模式 语音+背景音乐 通常在12~20kbps时自动切换到混合模式 举例：当你讲话时使用SILK，如果背景是音乐则自动激活CELT，两者混合。
四、Opus在视频会议中的作用 在视频会议中，Opus是极其理想的音频编码器：
优势 实际意义 低延迟 说话和听到之间的时延最小化 容错强 丢包情况下能保持音质，可搭配FEC（前向纠错）与PLC（丢包隐藏） 动态码率 网络条件不好时能自动降低码率，避免卡顿 自适应带宽 支持从窄带（NB）到全带（FB） 内置VBR/CBR 适应不同传输通道，比如WebRTC、UDP传输等 五、Opus的实际使用（如在客户端） 在iOS/macOS视频会议客户端中，使用Opus通常流程如下：
采集音频（AVAudioEngine / AudioQueue / AudioUnit） ↓ 送入Opus编码器（libopus） ↓ 生成压缩数据（6～64kbps） ↓ 通过网络发送（RTP / WebSocket / UDP） ↓ 远端收到后用Opus解码器还原音频 ↓ 播放音频（AudioUnit / AVAudioPlayerNode） 示例接口（用libopus） // 初始化编码器 OpusEncoder *encoder; encoder = opus_encoder_create(48000, 1, OPUS_APPLICATION_VOIP, &amp;error); // 编码PCM数据 int numBytes = opus_encode(encoder, pcm_input, frame_size, output_buffer, max_data_bytes); // 解码 int decodedSamples = opus_decode(decoder, encoded_data, length, pcm_output, frame_size, 0); 你通常需要处理：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to Opus音频编解码器详解" href=https://xuyafei.github.io/personal-site/posts/opus_codec/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>音频采样率与码率详解</h2></header><div class=entry-content><p>音频采样率与码率详解 一、基本概念区分 1. 采样率（Sampling Rate） 描述的是每秒采集多少次声音的幅度（单位：Hz） 影响的是音频频率范围（最高频率 = 采样率 / 2） 2. 码率（Bitrate） 描述的是每秒传输/存储多少数据（单位：kbps） 影响的是音频的清晰度和压缩率 二、类比解释：录音=画素描 假设你在"素描一条曲线"：
概念 类比 意义 采样率 你每秒画多少个点 画得越密，越能还原细节；越稀疏，线条会失真 码率 你用多少"字节"描述每个点 比如你用2个字节画点，还是压缩成0.5个字节 三、采样率详解 1. 基本概念 人耳能听到的范围是：20Hz – 20kHz 常见采样率： 8000Hz（8kHz）：只适合电话语音，频率范围到4kHz 16000Hz（16kHz）：清晰语音 44100Hz（44.1kHz）：CD音质，适合音乐 48000Hz（48kHz）：专业音频/视频会议常用 2. 奈奎斯特定理 $$ f_s \geq 2f_{max} $$ 其中：
$f_s$ 是采样率 $f_{max}$ 是信号最高频率 3. 采样率选择的影响 采样率 最高频率 适用场景 数据量 8kHz 4kHz 电话语音 最小 16kHz 8kHz 语音通话 较小 44.1kHz 22.05kHz 音乐播放 中等 48kHz 24kHz 专业音频 较大 96kHz 48kHz 录音室 最大 四、码率详解 1. 基本概念 码率决定了音频最终数据大小，也受编码压缩算法影响：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 音频采样率与码率详解" href=https://xuyafei.github.io/personal-site/posts/audio_sampling_bitrate/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>音频丢包恢复机制详解：PLC与FEC技术</h2></header><div class=entry-content><p>音频丢包恢复机制详解：PLC与FEC技术 一、概述 在实时音频传输中，网络丢包是常见问题。为了提供流畅的音频体验，业界开发了多种丢包恢复机制，其中PLC（Packet Loss Concealment）和FEC（Forward Error Correction）是最重要的两种技术。本文将深入解析这两种技术的原理、实现和应用。
二、Packet Loss Concealment (PLC) 1. 核心目的 当某一帧音频数据丢失时，无需重传或额外带宽，用已有信息在接收端"伪造"出一帧音频，尽量减少听觉冲击，保持声音的连续性和自然感。
2. 实现原理 2.1 时间域复制（简单策略） 方法：将上一帧音频直接拷贝作为当前帧输出 优点：实现简单、快速 缺点：只适合语音持续不变的段落，不适用于突变声音（如爆破、音乐） 2.2 线性预测 + 谱包络合成（复杂策略） 使用历史帧的语音参数（LPC、pitch周期）估计当前音频特性 预测当前帧的激励信号（residual） 用线性预测编码器（LPC）合成语音波形 适用于Opus、G.729等编码器 效果好很多，尤其对语音频率变化有较好适应能力 3. Opus中的PLC实现 3.1 工作流程 每帧编码时保存编码前的状态（LPC、谱参数等） 丢包后： 单帧丢失：自动触发PLC 使用预测+周期分析合成语音 输出一帧近似真实的音频 3.2 局限性 情况 PLC效果 单帧丢失（20ms以内） 几乎无感知 连续两帧丢失（40ms） 能容忍，但会模糊变形 连续三帧以上（>60ms） 明显失真、机械音 语速突变/背景变化剧烈 无法预测，噪声增加 4. 应用场景 WebRTC语音通信（内建支持） VoIP电话系统（如SIP） 音视频会议（搭配FEC一起用） 实时对讲、语音助手 三、Forward Error Correction (FEC) 1. 核心目的 在发送端加入多余冗余信息，即使一部分原始数据丢失，也能从剩下的数据中还原完整帧，从而无需重传即可实现丢包恢复。
2. 实现原理 2.1 基本机制 以异或校验为例：
发送三帧音频数据：A、B、C 添加校验帧：D = A ⊕ B ⊕ C 如果B丢失，可通过D ⊕ A ⊕ C = B恢复 2.2 常用编码技术 Reed-Solomon（RS）编码 Convolutional Coding XOR-based ULPFEC（RTP层） Opus In-band FEC（音频层） 3. Opus In-band FEC 3.1 工作原理 第N帧中附带了第N-1帧的冗余 如果第N-1帧丢失，但第N帧到达，可用其恢复上一帧 延迟增加10ms，但完全不需要重传 3.2 使用条件 码率必须高于阈值（>16kbps）
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 音频丢包恢复机制详解：PLC与FEC技术" href=https://xuyafei.github.io/personal-site/posts/audio_loss_recovery/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>音频数字化：采样与量化详解</h2></header><div class=entry-content><p>音频数字化：采样与量化详解 一、概述 在数字音频处理中，采样（Sampling）和量化（Quantization）是两个最基础也是最重要的概念。它们共同完成了将模拟声音信号转换为数字信号的过程。本文将深入解析这两个概念，从原理到实践，帮助读者全面理解音频数字化的过程。
二、采样（Sampling） 1. 什么是采样？ 采样是将连续的模拟信号转换为离散的数字信号的过程。在音频领域，这意味着将连续的声波转换为一系列离散的数值。
声音的物理本质 声音最初是空气中的连续压力波：
人说话 → 声带振动 → 空气分子震动 → 在空间中传播形成声波 这时还没有"数值"的概念，是纯粹的物理变化（压力） 这种连续的物理波动称为模拟信号（Analog Signal） 麦克风的作用 麦克风将"空气压力波"转换成电压信号：
声音使麦克风振膜震动 麦克风将振动转换为电压：某一瞬间 = 某个电压值 比如：+0.8V、-1.2V 等 这些电压通常被限制在一个范围内（如 -2.5V 到 +2.5V） 超出这个范围会削波（clipping，造成失真） 这个范围是声卡或 ADC 硬件的输入参考电压 生动的类比 想象你在看电影：
模拟信号就像电影胶片，画面是连续的 采样就像把胶片转换成数字视频，每秒截取24帧画面 采样率越高，就像每秒截取的画面越多，动作越流畅 2. 采样率（Sampling Rate） 采样率决定了每秒采集多少个数据点。
采样率 每秒采样次数 应用场景 44.1 kHz 44,100次 CD音质 48 kHz 48,000次 专业设备/视频音轨 96 kHz 96,000次 高保真录音 192 kHz 192,000次 超高保真录音 通俗解释 采样率就像"拍照频率"：
44.1 kHz 意味着每秒"拍"44,100张"声音照片" 采样率越高，抓住的声音细节越多 就像高速摄影机，可以捕捉到更细微的变化 3. 奈奎斯特定律（Nyquist Theorem） 奈奎斯特定律是采样理论的基础：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 音频数字化：采样与量化详解" href=https://xuyafei.github.io/personal-site/posts/audio_sampling_quantization/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://xuyafei.github.io/personal-site/>我的博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
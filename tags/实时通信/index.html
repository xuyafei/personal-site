<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>实时通信 | 我的博客</title>
<meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://xuyafei.github.io/personal-site/tags/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1/><link crossorigin=anonymous href=/personal-site/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://xuyafei.github.io/personal-site/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://xuyafei.github.io/personal-site/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://xuyafei.github.io/personal-site/favicon-32x32.png><link rel=apple-touch-icon href=https://xuyafei.github.io/personal-site/apple-touch-icon.png><link rel=mask-icon href=https://xuyafei.github.io/personal-site/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://xuyafei.github.io/personal-site/tags/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1/index.xml><link rel=alternate hreflang=en href=https://xuyafei.github.io/personal-site/tags/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAYQHy+K8nqKdr1EzvFzSQC+TAXx6gNQgoRxKtj+P9vvCCQTRWiV crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><script>MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta property="og:url" content="https://xuyafei.github.io/personal-site/tags/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1/"><meta property="og:site_name" content="我的博客"><meta property="og:title" content="实时通信"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="实时通信"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xuyafei.github.io/personal-site/ accesskey=h title="我的博客 (Alt + H)">我的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://xuyafei.github.io/personal-site/categories/ title=分类><span>分类</span></a></li><li><a href=https://xuyafei.github.io/personal-site/tags/ title=标签><span>标签</span></a></li><li><a href=https://xuyafei.github.io/personal-site/archives/ title=归档><span>归档</span></a></li><li><a href=https://xuyafei.github.io/personal-site/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://xuyafei.github.io/personal-site/>Home</a>&nbsp;»&nbsp;<a href=https://xuyafei.github.io/personal-site/tags/>标签</a></div><h1>实时通信
<a href=/personal-site/tags/%E5%AE%9E%E6%97%B6%E9%80%9A%E4%BF%A1/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>视频会议系统核心技术详解</h2></header><div class=entry-content><p>视频会议系统核心技术详解 视频会议系统是一个复杂的实时通信系统，涉及多个技术领域的协同工作。本文将深入探讨视频会议系统的核心技术模块，包括音视频采集编码、网络传输、解码渲染、信令控制、多人协同等关键技术，以及在实际应用中的挑战与解决方案。
一、视频会议的关键技术模块总览 技术架构层级 层级 技术模块 说明 1️⃣ 采集与编码 摄像头采集、音频采集、音视频编码 获取原始数据并压缩 2️⃣ 网络传输 RTP/RTCP、WebRTC、NAT穿透、网络自适应 实时传输数据，解决丢包、延迟等问题 3️⃣ 解码与渲染 解码器（硬件/软件）、OpenGL/Metal渲染 把压缩数据还原并显示出来 4️⃣ 信令与控制 房间管理、入会/退会、媒体协商、ICE 控制会话建立、媒体通道建立 5️⃣ 多人协同与混流 MCU/SFU、音视频混合转发、多画面布局 支持多人会议、减少带宽消耗 6️⃣ 附加功能 屏幕共享、白板、录制、虚拟背景、美颜 提升会议体验 二、关键技术细节拆解 1. 音视频采集与编码 音频采集 采集设备：系统音频设备（麦克风） 采样参数： 采样率：通常为 48kHz 采样位深：16bit/24bit 声道数：单声道/立体声 音频处理： 回声消除（AEC） 噪声抑制（NS） 自动增益控制（AGC） 视频采集 采集接口： Qt Multimedia AVFoundation（iOS/macOS） DirectShow（Windows） V4L2（Linux） 采集参数： 分辨率：720p/1080p/4K 帧率：15/24/30/60fps 色彩空间：YUV420/NV12 图像处理： 自动对焦 白平衡 曝光控制 编码技术 视频编码：
H.264/AVC H.265/HEVC VP8/VP9 AV1 音频编码：
Opus（推荐） AAC G.711 G.722 编码优化：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 视频会议系统核心技术详解" href=https://xuyafei.github.io/personal-site/posts/video_conference_technology/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Opus音频编解码器详解</h2></header><div class=entry-content><p>Opus音频编解码器详解 一、什么是Opus？ Opus是一种专为实时音频通信设计的开放、免版权费的音频编解码器，由IETF标准化（RFC 6716）。
主要优势 低延迟（最小5ms） 高音质（语音、音乐都很优秀） 自适应码率、采样率、帧长 适合语音和全频音乐（宽频甚至超宽频） 广泛应用于WebRTC、Zoom、Discord、Google Meet、Skype等 二、Opus的核心特性 特性 说明 支持采样率 8kHz ～ 48kHz 支持声道 单声道（mono）、立体声（stereo） 支持码率 6kbps ～ 510kbps（可变/恒定） 支持帧长 2.5ms、5ms、10ms、20ms、40ms、60ms 自适应编码模式 SILK（语音）、CELT（音乐）、混合模式（语音中带音乐） 可封装格式 Ogg、WebM、RTP 三、Opus是如何工作的？ Opus融合了两种技术，根据内容自动选择编码方式：
模块 用于 描述 SILK 语音 来自Skype，适合低码率、人声编码 CELT 音乐 基于MDCT的宽频音频压缩，适合音乐和高保真音频 混合模式 语音+背景音乐 通常在12~20kbps时自动切换到混合模式 举例：当你讲话时使用SILK，如果背景是音乐则自动激活CELT，两者混合。
四、Opus在视频会议中的作用 在视频会议中，Opus是极其理想的音频编码器：
优势 实际意义 低延迟 说话和听到之间的时延最小化 容错强 丢包情况下能保持音质，可搭配FEC（前向纠错）与PLC（丢包隐藏） 动态码率 网络条件不好时能自动降低码率，避免卡顿 自适应带宽 支持从窄带（NB）到全带（FB） 内置VBR/CBR 适应不同传输通道，比如WebRTC、UDP传输等 五、Opus的实际使用（如在客户端） 在iOS/macOS视频会议客户端中，使用Opus通常流程如下：
采集音频（AVAudioEngine / AudioQueue / AudioUnit） ↓ 送入Opus编码器（libopus） ↓ 生成压缩数据（6～64kbps） ↓ 通过网络发送（RTP / WebSocket / UDP） ↓ 远端收到后用Opus解码器还原音频 ↓ 播放音频（AudioUnit / AVAudioPlayerNode） 示例接口（用libopus） // 初始化编码器 OpusEncoder *encoder; encoder = opus_encoder_create(48000, 1, OPUS_APPLICATION_VOIP, &amp;error); // 编码PCM数据 int numBytes = opus_encode(encoder, pcm_input, frame_size, output_buffer, max_data_bytes); // 解码 int decodedSamples = opus_decode(decoder, encoded_data, length, pcm_output, frame_size, 0); 你通常需要处理：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to Opus音频编解码器详解" href=https://xuyafei.github.io/personal-site/posts/opus_codec/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>音频采样率与码率详解</h2></header><div class=entry-content><p>音频采样率与码率详解 一、基本概念区分 1. 采样率（Sampling Rate） 描述的是每秒采集多少次声音的幅度（单位：Hz） 影响的是音频频率范围（最高频率 = 采样率 / 2） 2. 码率（Bitrate） 描述的是每秒传输/存储多少数据（单位：kbps） 影响的是音频的清晰度和压缩率 二、类比解释：录音=画素描 假设你在"素描一条曲线"：
概念 类比 意义 采样率 你每秒画多少个点 画得越密，越能还原细节；越稀疏，线条会失真 码率 你用多少"字节"描述每个点 比如你用2个字节画点，还是压缩成0.5个字节 三、采样率详解 1. 基本概念 人耳能听到的范围是：20Hz – 20kHz 常见采样率： 8000Hz（8kHz）：只适合电话语音，频率范围到4kHz 16000Hz（16kHz）：清晰语音 44100Hz（44.1kHz）：CD音质，适合音乐 48000Hz（48kHz）：专业音频/视频会议常用 2. 奈奎斯特定理 $$ f_s \geq 2f_{max} $$ 其中：
$f_s$ 是采样率 $f_{max}$ 是信号最高频率 3. 采样率选择的影响 采样率 最高频率 适用场景 数据量 8kHz 4kHz 电话语音 最小 16kHz 8kHz 语音通话 较小 44.1kHz 22.05kHz 音乐播放 中等 48kHz 24kHz 专业音频 较大 96kHz 48kHz 录音室 最大 四、码率详解 1. 基本概念 码率决定了音频最终数据大小，也受编码压缩算法影响：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 音频采样率与码率详解" href=https://xuyafei.github.io/personal-site/posts/audio_sampling_bitrate/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>网络抖动与Jitter Buffer详解</h2></header><div class=entry-content><p>网络抖动与Jitter Buffer详解 一、网络抖动（Jitter）基础 1. 基本概念 Jitter是指连续接收的RTP包之间到达时间的不稳定性。即：包与包之间的间隔时间发生波动，这可能导致音视频播放时出现"卡顿"“破音"或"花屏”。
2. 实例说明 假设一个音频流每20ms发一个RTP包：
理想情况：客户端每20ms收到一个RTP包 实际情况（有jitter）： 第1包：20ms后到达 第2包：25ms后到达（延迟了） 第3包：15ms后到达（提前了） 虽然没有丢包，但由于间隔不一致，接收端播放就变得不流畅。
3. Jitter的重要性 音视频数据是实时连续的，如果jitter很大：
需要更大的jitter buffer来重新排序、平滑播放 会增加延迟，影响实时性 jitter spike（剧烈抖动）会直接影响用户体验 二、Jitter的计算方法 1. RTP中的Jitter估算 RTP协议建议如下的估算公式（用于RTCP报告）：
假设：
$R_i$：第i个包的实际接收时间 $S_i$：第i个包的RTP时间戳（按采样时钟计算） $D_i = (R_i - R_{i-1}) - (S_i - S_{i-1})$：间隔差值 Jitter的估计采用指数加权平均： $$ Jitter = Jitter_{prev} + \frac{|D_i| - Jitter_{prev}}{16} $$
2. Jitter的评估标准 Jitter值（音频RTP） 网络状况 &lt; 20ms（≈160帧单位） 非常好 20ms~50ms 可接受 50ms~100ms 明显波动，需要大buffer >100ms 严重不稳定，可能影响同步 三、RTCP丢包统计 1. RTCP RR中的丢包相关字段 字段名 含义 fraction_lost 最近一段时间内丢包的比例（0~255） cumulative_lost 总丢包数（自会话开始以来） extended_highest_seq_num 接收到的最大序列号 jitter 当前估算的jitter 2. 丢包率计算 假设：
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 网络抖动与Jitter Buffer详解" href=https://xuyafei.github.io/personal-site/posts/network_jitter_buffer/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>视频会议系统的网络自适应机制详解</h2></header><div class=entry-content><p>视频会议系统的网络自适应机制详解 一、概述 网络自适应机制是视频会议系统的关键组成部分，目标是根据网络质量动态调整编码策略，保证音视频流畅、清晰、不卡顿。本文将从多个层面系统讲解网络自适应的关键技术。
二、码率控制（Bitrate Control） 1. 基本模式 1.1 恒定码率（CBR）vs 可变码率（VBR） 模式 特点 适用场景 CBR 保持稳定的码率，不随内容和网络变化 带宽受限场景 VBR 根据内容复杂度调整码率，压缩效率更高 带宽充足场景 1.2 实时控制方式 使用反馈信息（如RTCP或自定义带宽估计模块）调整编码器目标码率 当网络变差时，主动降低目标码率，减少丢包、卡顿 编码器内部调整： 量化参数QP：提高压缩比，牺牲画质 编码复杂度：减少参考帧、运动估计区域 2. 码率控制算法 2.1 基于延迟的拥塞控制 $$ TargetBitrate = CurrentBitrate \times (1 - \frac{Delay}{MaxDelay}) $$
2.2 基于丢包的拥塞控制 $$ TargetBitrate = CurrentBitrate \times (1 - \frac{PacketLoss}{MaxLoss}) $$
三、丢包策略与恢复机制 1. 丢包感知 通过RTCP Receiver Report汇总丢包率（fraction lost） 通过WebRTC的RTCIceCandidateStats、RTCInboundRTPStreamStats获取实时丢包信息 2. 音视频丢包恢复方法 2.1 音频恢复技术 技术 说明 适用场景 PLC 使用前一帧音频平滑过渡填补丢帧 单帧丢失 FEC 发送冗余包，接收端可恢复少量丢包 低丢包率 DTX/CNG 静音时节省带宽，插值恢复静音段 静音场景 2.2 视频恢复技术 技术 说明 适用场景 NACK 请求关键丢包重传，延迟可控前提下有效 关键帧丢失 FEC 加入纠错包 低丢包率 SVC 分层视频结构，核心层可独立解码 带宽波动 IDR 网络恢复时，强制送一帧关键帧 严重丢包 3. 详细技术分析 3.1 PLC（Packet Loss Concealment） 使用前一帧或一小段连续帧生成"合成音" 常见方法： 重复前一帧 谱估计 + 预测合成 应用： Opus编码器内部PLC能力 优点：无延迟、无带宽开销 缺点：连续丢包效果变差 3.2 FEC（Forward Error Correction） 多发送冗余包（如X + Y + Z + “X⊕Y⊕Z”） Opus支持内建FEC（in-band FEC） 适合丢包率3~10%，延迟容忍较低（&lt;100ms）的场景 3.3 NACK（Negative Acknowledgement） 接收端通过RTCP或TWCC上报缺失帧编号 适用： 网络质量稳定 丢包不频繁 限制： 增加延迟 带宽拥塞时可能失败 四、带宽估计（Bandwidth Estimation） 1. 基本原理 通过测量接收/发送包的间隔、大小、丢包率、延迟变化等估算当前网络带宽。
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 视频会议系统的网络自适应机制详解" href=https://xuyafei.github.io/personal-site/posts/network_adaptation/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>音频丢包恢复机制详解：PLC与FEC技术</h2></header><div class=entry-content><p>音频丢包恢复机制详解：PLC与FEC技术 一、概述 在实时音频传输中，网络丢包是常见问题。为了提供流畅的音频体验，业界开发了多种丢包恢复机制，其中PLC（Packet Loss Concealment）和FEC（Forward Error Correction）是最重要的两种技术。本文将深入解析这两种技术的原理、实现和应用。
二、Packet Loss Concealment (PLC) 1. 核心目的 当某一帧音频数据丢失时，无需重传或额外带宽，用已有信息在接收端"伪造"出一帧音频，尽量减少听觉冲击，保持声音的连续性和自然感。
2. 实现原理 2.1 时间域复制（简单策略） 方法：将上一帧音频直接拷贝作为当前帧输出 优点：实现简单、快速 缺点：只适合语音持续不变的段落，不适用于突变声音（如爆破、音乐） 2.2 线性预测 + 谱包络合成（复杂策略） 使用历史帧的语音参数（LPC、pitch周期）估计当前音频特性 预测当前帧的激励信号（residual） 用线性预测编码器（LPC）合成语音波形 适用于Opus、G.729等编码器 效果好很多，尤其对语音频率变化有较好适应能力 3. Opus中的PLC实现 3.1 工作流程 每帧编码时保存编码前的状态（LPC、谱参数等） 丢包后： 单帧丢失：自动触发PLC 使用预测+周期分析合成语音 输出一帧近似真实的音频 3.2 局限性 情况 PLC效果 单帧丢失（20ms以内） 几乎无感知 连续两帧丢失（40ms） 能容忍，但会模糊变形 连续三帧以上（>60ms） 明显失真、机械音 语速突变/背景变化剧烈 无法预测，噪声增加 4. 应用场景 WebRTC语音通信（内建支持） VoIP电话系统（如SIP） 音视频会议（搭配FEC一起用） 实时对讲、语音助手 三、Forward Error Correction (FEC) 1. 核心目的 在发送端加入多余冗余信息，即使一部分原始数据丢失，也能从剩下的数据中还原完整帧，从而无需重传即可实现丢包恢复。
2. 实现原理 2.1 基本机制 以异或校验为例：
发送三帧音频数据：A、B、C 添加校验帧：D = A ⊕ B ⊕ C 如果B丢失，可通过D ⊕ A ⊕ C = B恢复 2.2 常用编码技术 Reed-Solomon（RS）编码 Convolutional Coding XOR-based ULPFEC（RTP层） Opus In-band FEC（音频层） 3. Opus In-band FEC 3.1 工作原理 第N帧中附带了第N-1帧的冗余 如果第N-1帧丢失，但第N帧到达，可用其恢复上一帧 延迟增加10ms，但完全不需要重传 3.2 使用条件 码率必须高于阈值（>16kbps）
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 音频丢包恢复机制详解：PLC与FEC技术" href=https://xuyafei.github.io/personal-site/posts/audio_loss_recovery/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>视频传输中的丢包恢复机制：NACK与FEC详解</h2></header><div class=entry-content><p>视频传输中的丢包恢复机制：NACK与FEC详解 一、概述 在实时视频传输中，网络丢包是影响视频质量的主要因素之一。为了提供流畅的视频体验，业界开发了多种丢包恢复机制，其中NACK（Negative Acknowledgement）和FEC（Forward Error Correction）是最重要的两种技术。本文将深入解析这两种技术的原理、实现和应用场景。
二、NACK（Negative Acknowledgement） 1. 定义与原理 NACK是一种基于反馈的重传机制，接收端通过发送否定确认来请求发送端重传丢失的数据包。
2. 工作流程 发送端通过RTP发送媒体包（视频RTP包） 接收端RTP解包时检测缺失序号 例如：收到序号100、101、103，说明102丢失 接收端构建RTCP NACK消息，发送回发送端 发送端根据缓存重新发送丢失的RTP包 3. 应用条件与限制 项目 描述 ✅ 适合场景 偶发性、低延迟网络中的小范围丢包 ❌ 不适合场景 丢包严重、时延较高（≥250ms） 限制条件 发送端必须有RTP重传缓存（200~500ms） 延迟影响 至少一倍RTT（往返时延）才能恢复该帧 4. 优缺点分析 优点 缺点 节省带宽（只在丢包时重传） 恢复存在RTT延迟 精准修复 高丢包下效率低 简单易实现 要求发送端有缓存 5. 实际应用 WebRTC支持基于RTCP NACK的重传机制 主要用于关键帧或参考帧的恢复 通常与RTP Retransmission (RTX)配合使用 使用新的SSRC和负载类型 三、视频FEC（Forward Error Correction） 1. 定义与原理 FEC是一种前向纠错机制，发送端在发送时附加冗余信息，使得接收端可以自行恢复丢失的数据，无需重传。
2. 常见类型 ULPFEC（RFC 5109）
用于RTP层的传统视频FEC 支持冗余帧压缩 FlexFEC（WebRTC推荐）
支持任意帧布局 灵活性强，效率更高 Reed-Solomon / XOR
...</p></div><footer class=entry-footer><span title='2024-04-22 00:00:00 +0000 UTC'>April 22, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;徐亚飞</footer><a class=entry-link aria-label="post link to 视频传输中的丢包恢复机制：NACK与FEC详解" href=https://xuyafei.github.io/personal-site/posts/video_loss_recovery/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://xuyafei.github.io/personal-site/>我的博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>